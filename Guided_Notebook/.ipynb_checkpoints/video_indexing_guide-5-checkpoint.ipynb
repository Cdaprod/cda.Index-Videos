{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0649bd79",
   "metadata": {},
   "source": [
    "\n",
    "# Video Indexing, Embedding, and Metadata Generation\n",
    "\n",
    "This guide aims to walk you through a comprehensive pipeline for video data processing. You'll learn how to:\n",
    "\n",
    "1. Generate initial video metadata.\n",
    "2. Extract key frames from videos.\n",
    "3. Calculate embeddings for these frames using ResNet50 and GPT-3.\n",
    "4. Generate additional metadata using a Language Model.\n",
    "5. Update the metadata to a JSON file, Supabase, and Weaviate.\n",
    "\n",
    "All the code is idempotent, meaning you can run it multiple times without worrying about duplicate data. So let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9dcfd",
   "metadata": {},
   "source": [
    "\n",
    "## Video Indexing\n",
    "\n",
    "The first step in our pipeline is to generate initial metadata for our videos. This includes basic information like filename, type, source path, frame rate, original resolution, and whether the video has audio. The metadata serves as the foundation for all subsequent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b2b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:\\\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create a Path object for the mounted NAS directory\n",
    "nas_path = Path(r\"S:\\\\\")\n",
    "\n",
    "(nas_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2501d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define Pydantic model for video metadata\n",
    "class VideoMetadata(BaseModel):\n",
    "    filename: str\n",
    "    type: str\n",
    "    src_path: str\n",
    "    frame_rate: int\n",
    "    original_resolution: str\n",
    "    has_audio: bool\n",
    "\n",
    "# Function to index all video files in a directory and generate metadata\n",
    "def index_videos(root_directory):\n",
    "    video_files = []\n",
    "    video_metadata_list = []\n",
    "    \n",
    "    # Traverse root directory to find all video files\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.mp4', '.mkv', '.flv', '.avi')):\n",
    "                video_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Generate metadata for each video file\n",
    "    for video_file in video_files:\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "        frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        resolution = f'{width}x{height}'\n",
    "        has_audio = True  # This is a placeholder. Actual check for audio stream needed.\n",
    "        \n",
    "        video_metadata = VideoMetadata(\n",
    "            filename=os.path.basename(video_file),\n",
    "            type=os.path.splitext(video_file)[1][1:],\n",
    "            src_path=video_file,\n",
    "            frame_rate=frame_rate,\n",
    "            original_resolution=resolution,\n",
    "            has_audio=has_audio\n",
    "        )\n",
    "        \n",
    "        video_metadata_list.append(video_metadata.dict())\n",
    "    \n",
    "    return video_metadata_list\n",
    "\n",
    "# Sample usage\n",
    "root_directory = (r'S:\\\\')\n",
    "# root_directory = '/volume1'  # Replace with your actual root directory\n",
    "\n",
    "# To source the USER's HOME Directory on Linux and Windows\n",
    "# home_directory = os.getenv(\"HOME\") or os.getenv(\"USERPROFILE\")\n",
    "\n",
    "video_metadata_list = index_videos(root_directory)\n",
    "\n",
    "# Convert metadata list to JSON and save\n",
    "json_file_path = os.path.join(current_directory, 'index_vidoes.json')\n",
    "# json_file_path = '$PWD/indexed_videos.json'  # Replace with your actual JSON file path\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(video_metadata_list, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeec7d5",
   "metadata": {},
   "source": [
    "\n",
    "## Frame Extraction\n",
    "\n",
    "Once we have the basic metadata, we move on to frame extraction. We'll be using key framing to minimize the number of frames needed for analysis. The extracted frames will be stored as numpy arrays in a directory for easy retrieval and further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to extract key frames from video\n",
    "def extract_key_frames(video_path, save_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Your key frame extraction logic here\n",
    "        # For demonstration, we'll save every 10th frame\n",
    "        \n",
    "        frame_id = int(cap.get(1))  # Current frame number\n",
    "        if frame_id % 10 == 0:\n",
    "            frame_file = os.path.join(save_path, f'frame_{frame_id}.npy')\n",
    "            np.save(frame_file, frame)\n",
    "            frames.append({'frame_id': frame_id, 'frame_path': frame_file})\n",
    "    \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "# Sample usage\n",
    "video_path = '/path/to/sample_video.mp4'\n",
    "frame_save_path = '/path/to/save/frames'\n",
    "\n",
    "# Create directory to save frames if it doesn't exist\n",
    "if not os.path.exists(frame_save_path):\n",
    "    os.makedirs(frame_save_path)\n",
    "\n",
    "key_frames = extract_key_frames(video_path, frame_save_path)\n",
    "print(key_frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74fa5c",
   "metadata": {},
   "source": [
    "\n",
    "## Embedding Calculation\n",
    "\n",
    "After extracting the key frames, the next step is to calculate their embeddings. We'll be using both ResNet50 and GPT-3 to generate these embeddings. These embeddings will serve as a compact representation of the frames and will be used for various downstream tasks like search, categorization, and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder code for Embedding Calculation\n",
    "# Here you would add the code to calculate ResNet50 and GPT-3 embeddings for the extracted frames\n",
    "# For demonstration, let's assume we have a function `calculate_embeddings` that takes a frame path and returns the embeddings\n",
    "\n",
    "def calculate_embeddings(frame_path):\n",
    "    # Your actual embedding calculation logic here\n",
    "    return 'sample_embedding'\n",
    "\n",
    "# Calculate embeddings for key frames\n",
    "frame_embeddings = {frame['frame_id']: calculate_embeddings(frame['frame_path']) for frame in key_frames}\n",
    "print(frame_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b889b3",
   "metadata": {},
   "source": [
    "\n",
    "## LLM Data Generation\n",
    "\n",
    "Once we have the embeddings, we can proceed to enrich our video metadata using a Language Model. We'll be using GPT-3 for this task. The Language Model will generate a summary, description, keywords, category, and creator for each video, which will be added to our metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder code for LLM Data Generation\n",
    "# Here you would add the code to generate additional metadata like Summary, Description, Keywords, etc., using a Language Model\n",
    "# For demonstration, let's assume we have a function `generate_llm_data` that takes an embedding and returns the additional metadata\n",
    "\n",
    "def generate_llm_data(embedding):\n",
    "    # Your actual LLM data generation logic here\n",
    "    return {\n",
    "        'Summary': 'sample_summary',\n",
    "        'Description': 'sample_description',\n",
    "        'Keywords': ['sample_keyword1', 'sample_keyword2'],\n",
    "        'Category': 'sample_category',\n",
    "        'Creator': 'sample_creator'\n",
    "    }\n",
    "\n",
    "# Generate LLM data for key frames\n",
    "llm_data = {frame['frame_id']: generate_llm_data(frame_embeddings[frame['frame_id']]) for frame in key_frames}\n",
    "print(llm_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed29be",
   "metadata": {},
   "source": [
    "\n",
    "## Updating JSON File\n",
    "\n",
    "All the metadata, frame paths, and embeddings will be consolidated and stored in a JSON file. We'll be using a nested JSON structure to keep the data organized. The JSON file will be updated in an idempotent manner, ensuring that running the code multiple times does not create duplicate entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3015e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/local/bin/python3\n",
    "\n",
    "import json\n",
    "\n",
    "# Function to update JSON file in an idempotent manner\n",
    "def update_json_file(json_file_path, new_data):\n",
    "    # Read existing data from JSON file\n",
    "    if os.path.exists(json_file_path):\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            existing_data = json.load(f)\n",
    "    else:\n",
    "        existing_data = {}\n",
    "    \n",
    "    # Update existing data with new data\n",
    "    for video_id, metadata in new_data.items():\n",
    "        if video_id not in existing_data:\n",
    "            existing_data[video_id] = {}\n",
    "        existing_data[video_id].update(metadata)\n",
    "    \n",
    "    # Write updated data back to JSON file\n",
    "    with open(json_file_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "# Sample usage\n",
    "new_data = {\n",
    "    \"some_unique_video_id\": {\n",
    "        \"metadata\": video_metadata.dict(),  # This would come from your actual metadata\n",
    "        \"key_frames\": key_frames,\n",
    "        \"frame_embeddings\": frame_embeddings,\n",
    "        \"llm_data\": llm_data\n",
    "    }\n",
    "}\n",
    "\n",
    "# Update JSON file with new data\n",
    "json_file_path = '/path/to/indexed_videos.json'  # Replace with your actual JSON file path\n",
    "update_json_file(json_file_path, new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eed27c",
   "metadata": {},
   "source": [
    "\n",
    "## Updating Supabase and Weaviate\n",
    "\n",
    "Finally, all the generated and collected data will be updated to Supabase and Weaviate databases. This will allow us to efficiently query and retrieve video data for various applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder code for Database Updating\n",
    "# Here you would add the code to update Supabase and Weaviate databases with the new data\n",
    "# You can use the Python SDKs for both Supabase and Weaviate to accomplish this\n",
    "\n",
    "# Sample Supabase code (placeholder)\n",
    "# supabase = create_client(SUPABASE_URL, SUPABASE_API_KEY)\n",
    "# response = supabase.table('videos').upsert(new_data)\n",
    "\n",
    "# Sample Weaviate code (placeholder)\n",
    "# client = weaviate.Client(WEAVIATE_URL)\n",
    "# client.batch.create(new_data)\n",
    "\n",
    "# Note: Make sure to replace the placeholder code with your actual implementation for database updates\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
