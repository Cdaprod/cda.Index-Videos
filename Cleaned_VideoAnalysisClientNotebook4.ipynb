{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb83488",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "  \"classes\": [\n",
    "    {\n",
    "      \"class\": \"IndexedVideos\",\n",
    "      \"properties\": [\n",
    "        {\n",
    "          \"name\": \"filename\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"index_number\",\n",
    "          \"dataType\": [\"int\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"src_path\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"type\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"class\": \"Videos\",\n",
    "      \"properties\": [\n",
    "        {\n",
    "          \"name\": \"category\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"creator\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"description\",\n",
    "          \"dataType\": [\"string\"],\n",
    "          \"vectorizer\": \"text2vec-contextionary\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"file_size\",\n",
    "          \"dataType\": [\"int\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"filename\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"frame_rate\",\n",
    "          \"dataType\": [\"float\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"frame_src_path\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"gpt3_embeddings\",\n",
    "          \"dataType\": [\"string\"],\n",
    "          \"vectorizer\": \"gpt3-vectorizer\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"has_audio\",\n",
    "          \"dataType\": [\"boolean\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"index_number\",\n",
    "          \"dataType\": [\"int\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"keywords\",\n",
    "          \"dataType\": [\"string\"],\n",
    "          \"vectorizer\": \"text2vec-contextionary\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"original_resolution\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"resnet50_embeddings\",\n",
    "          \"dataType\": [\"string\"],\n",
    "          \"vectorizer\": \"resnet50-vectorizer\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"src_path\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"summary\",\n",
    "          \"dataType\": [\"string\"],\n",
    "          \"vectorizer\": \"text2vec-contextionary\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"type\",\n",
    "          \"dataType\": [\"string\"]\n",
    "        }\n",
    "      ],\n",
    "      \"moduleConfig\": {\n",
    "        \"vectorization\": {\n",
    "          \"vectorizeClassName\": \"Videos\",\n",
    "          \"vectorizePropertyName\": [\"summary\", \"description\", \"resnet50_embeddings\", \"gpt3_embeddings\"]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0aac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your DataFrame schema here\n",
    "class VideoMetadata:\n",
    "    def __init__(self, filename, index_number, src_path, video_type):\n",
    "        self.filename = filename\n",
    "        self.index_number = index_number\n",
    "        self.src_path = src_path\n",
    "        self.video_type = video_type\n",
    "        self.category = None\n",
    "        self.creator = None\n",
    "        self.description = None\n",
    "        self.file_size = None\n",
    "        self.frame_rate = None\n",
    "        self.frame_src_path = None\n",
    "        self.gpt3_embeddings = None\n",
    "        self.has_audio = None\n",
    "        self.keywords = None\n",
    "        self.original_resolution = None\n",
    "        self.resnet50_embeddings = None\n",
    "        self.summary = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize your DataFrame here\n",
    "df_columns = ['filename', 'index_number', 'src_path', 'video_type', 'category', 'creator', 'description', 'file_size', 'frame_rate', 'frame_src_path', 'gpt3_embeddings', 'has_audio', 'keywords', 'original_resolution', 'resnet50_embeddings', 'summary']\n",
    "df = pd.DataFrame(columns=df_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to fetch videos and update DataFrame\n",
    "def fetch_videos():\n",
    "    # Fetch videos from your source\n",
    "    # Update the DataFrame df here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e807849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "def analyze_video(api_url, video_index):\n",
    "    response = requests.get(f'{api_url}/api/v1/videos/{video_index}')\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {'error': 'Failed to analyze video'}\n",
    "    \n",
    "# Main Controller\n",
    "api_url = 'http://your_flask_server_address_here'\n",
    "video_index = 1  # Replace with actual video index\n",
    "\n",
    "# Analyze Video\n",
    "analyzed_video = analyze_video(api_url, video_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e27b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to hold video metadata\n",
    "df = pd.DataFrame(columns=['filename', 'src_path', 'frame_rate', 'file_size', 'original_resolution', 'has_audio'])\n",
    "\n",
    "def extract_structural_metadata(video_paths):\n",
    "    global df\n",
    "    for video_path in video_paths:\n",
    "        # Open video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # Check if video opened successfully\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video file {video_path}\")\n",
    "            continue\n",
    "\n",
    "        # Get video details\n",
    "        frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        original_resolution = f\"{width}x{height}\"\n",
    "        \n",
    "        # Check for audio\n",
    "        # OpenCV doesn't provide a direct way to check for audio, \n",
    "        # so you may need to use other libraries or custom logic here\n",
    "        has_audio = None\n",
    "\n",
    "        # Get file size in bytes\n",
    "        file_size = None  # Use appropriate method to get file size\n",
    "        \n",
    "        # Update DataFrame\n",
    "        df = df.append({\n",
    "            'filename': video_path.split('/')[-1],\n",
    "            'src_path': video_path,\n",
    "            'frame_rate': frame_rate,\n",
    "            'file_size': file_size,\n",
    "            'original_resolution': original_resolution,\n",
    "            'has_audio': has_audio\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "        # Release the video capture object\n",
    "        cap.release()\n",
    "\n",
    "# Example usage\n",
    "video_paths = ['path/to/video1.mp4', 'path/to/video2.mp4']\n",
    "extract_structural_metadata(video_paths)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370dcc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_keyframes(df):\n",
    "    temp_dir = \"temp_frames\"\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    \n",
    "    frame_src_paths = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        video_path = row['src_path']\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        # Create a VideoCapture object\n",
    "        success, image = cap.read()\n",
    "        \n",
    "        # Loop to go through the frames and save keyframes\n",
    "        count = 0\n",
    "        frame_count = 0\n",
    "        while success:\n",
    "            success, image = cap.read()\n",
    "            if frame_count % 50 == 0:  # Save every 50th frame as a keyframe\n",
    "                frame_file_path = os.path.join(temp_dir, f\"frame_{count}_{row['filename']}.jpg\")\n",
    "                cv2.imwrite(frame_file_path, image)  # Save frame as JPEG file\n",
    "                frame_src_paths.append(frame_file_path)\n",
    "                count += 1\n",
    "            frame_count += 1\n",
    "\n",
    "    # Update DataFrame with frame_src_path\n",
    "    df['frame_src_path'] = frame_src_paths\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'filename': ['video1.mp4', 'video2.mp4'],\n",
    "    'src_path': ['/path/to/video1.mp4', '/path/to/video2.mp4'],\n",
    "    'frame_rate': [30, 25],\n",
    "    'file_size': [1024, 2048],\n",
    "    'original_resolution': ['1920x1080', '1280x720'],\n",
    "    'has_audio': [True, True]\n",
    "})\n",
    "\n",
    "# Call the function to extract keyframes and update the DataFrame\n",
    "extract_keyframes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07443c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d571001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the ResNet50 model\n",
    "resnet_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "def get_resnet50_embeddings(image_path):\n",
    "    # Read the image and resize it to ResNet-50 input dimensions\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Normalize the image\n",
    "    img = tf.keras.applications.resnet50.preprocess_input(img)\n",
    "    \n",
    "    # Get the embedding (Flatten the output to 1D array)\n",
    "    embedding = resnet_model.predict(img).flatten()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def update_dataframe_with_embeddings(df):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for frame_src_path in df['frame_src_path']:\n",
    "        embedding = get_resnet50_embeddings(frame_src_path)\n",
    "        all_embeddings.append(embedding)\n",
    "    \n",
    "    # Update DataFrame with resnet50_embeddings\n",
    "    df['resnet50_embeddings'] = all_embeddings\n",
    "\n",
    "# Sample DataFrame (Assuming that the 'frame_src_path' column was populated by the previous function)\n",
    "df = pd.DataFrame({\n",
    "    'filename': ['video1.mp4', 'video2.mp4'],\n",
    "    'src_path': ['/path/to/video1.mp4', '/path/to/video2.mp4'],\n",
    "    'frame_src_path': ['/path/to/frame1.jpg', '/path/to/frame2.jpg'],\n",
    "    # ... (other columns)\n",
    "})\n",
    "\n",
    "# Update the DataFrame with ResNet-50 embeddings\n",
    "update_dataframe_with_embeddings(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c85b0",
   "metadata": {},
   "source": [
    "# Future Improvements as Task Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c25c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskCreationChain:\n",
    "    def __init__(self):\n",
    "        self.tasks = []\n",
    "        \n",
    "    def add_task(self, name, description, priority, additional_notes=None):\n",
    "        task = {\n",
    "            'name': name,\n",
    "            'description': description,\n",
    "            'priority': priority,\n",
    "            'status': 'Not Started',\n",
    "            'additional_notes': additional_notes\n",
    "        }\n",
    "        self.tasks.append(task)\n",
    "    \n",
    "    def get_next_task(self):\n",
    "        # Sort tasks based on priority and return the first one\n",
    "        sorted_tasks = sorted(self.tasks, key=lambda x: x['priority'])\n",
    "        return sorted_tasks[0] if sorted_tasks else None\n",
    "    \n",
    "# Initialize the TaskCreationChain\n",
    "task_chain = TaskCreationChain()\n",
    "\n",
    "# Add tasks to the chain\n",
    "task_chain.add_task('Security & Authentication', 'Implement secure access to Weaviate and Postgres.', 1)\n",
    "task_chain.add_task('Error Handling', 'Implement comprehensive error handling and logging.', 2)\n",
    "task_chain.add_task('Data Validation', 'Validate incoming video files and metadata.', 3)\n",
    "task_chain.add_task('Data Backup', 'Implement data redundancy and backups.', 4)\n",
    "task_chain.add_task('Monitoring and Alerts', 'Set up monitoring and alerting tools.', 5)\n",
    "task_chain.add_task('Concurrency & Scalability', 'Handle multiple simultaneous requests.', 6)\n",
    "task_chain.add_task('Rate Limiting', 'Implement rate limiting.', 7)\n",
    "task_chain.add_task('Documentation', 'Create detailed API and codebase documentation.', 8)\n",
    "task_chain.add_task('UUID Management', 'Clarify UUID generation and usage.', 9)\n",
    "task_chain.add_task('Quality Assurance', 'Ensure metadata accuracy and consider human oversight.', 10)\n",
    "task_chain.add_task('Compliance', 'Check GDPR and other data protection regulations.', 11)\n",
    "task_chain.add_task('Versioning', 'Implement API and database schema versioning.', 12)\n",
    "task_chain.add_task('Batch Processing', 'Handle batch video upload and metadata extraction.', 13)\n",
    "task_chain.add_task('Cost Estimation', 'Estimate running costs of services.', 14)\n",
    "task_chain.add_task('Metadata Standards', 'Adhere to metadata standards for video files.', 15)\n",
    "task_chain.add_task('Testing', 'Implement unit, integration, and end-to-end tests.', 16)\n",
    "task_chain.add_task('Data Retention Policy', 'Define data retention and purging policies.', 17)\n",
    "task_chain.add_task('User Interface', 'Develop/Improve User Interface.', 18)\n",
    "\n",
    "# Retrieve the next task to execute\n",
    "next_task = task_chain.get_next_task()\n",
    "print(f\"Next task to execute: {next_task['name']}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
